{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "train.ipynb",
   "provenance": [
    {
     "file_id": "1ApGKLJ8X1Eff7fN5rfvAOaVW_LiUxTC8",
     "timestamp": 1619475297475
    },
    {
     "file_id": "1FWPmgiXBkiHv8MZ5MXfJiWX72UYGnIGH",
     "timestamp": 1618179268209
    },
    {
     "file_id": "1IiZ3PeOJpqlGOEfri5aWRZYBMUG_bBUx",
     "timestamp": 1617966714027
    }
   ],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8qhAEtbnUcj"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-N2KVrxezN0l"
   },
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import Isomap, LocallyLinearEmbedding\n",
    "from tqdm import tqdm"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leM4lP_6LGDi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620703295059,
     "user_tz": -120,
     "elapsed": 915,
     "user": {
      "displayName": "martinkozle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW9owaegS7VrgcH08bovw0wt8aoBH8W1Rbn9NI=s64",
      "userId": "00045613925661055538"
     }
    },
    "outputId": "a93caa38-00e4-42dd-e46e-43dc259f8c3f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQYfggZLnQW8"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cT5L4HOkVgnA"
   },
   "source": [
    "target_data_folder = '/data/Regression_target_data/'\n",
    "features_data_folder = '/data/Original_folds/'\n",
    "class_folder = '/classes/'\n",
    "\n",
    "labels =pd.read_csv(f\"{target_data_folder}labels.txt\",sep=';',index_col=False)\n",
    "sys_min = sys.float_info.min"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mO_L5Z9tasR8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620703298076,
     "user_tz": -120,
     "elapsed": 3919,
     "user": {
      "displayName": "martinkozle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW9owaegS7VrgcH08bovw0wt8aoBH8W1Rbn9NI=s64",
      "userId": "00045613925661055538"
     }
    },
    "outputId": "b8863871-8ea0-45e8-d3d4-ca6dc0638d48"
   },
   "source": [
    "!pip install physlearn"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: physlearn in /usr/local/lib/python3.7/dist-packages (1.2.2)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5-YD3-GuhvTc"
   },
   "source": [
    "import sys\n",
    "sys.path.append(class_folder)\n",
    "\n",
    "from decision_tree_singletarget import DecisionTree_Single\n",
    "from decision_tree_multitarget import DecisionTree_Multi\n",
    "from random_forest_singletarget import RandomForestRegressor_Single\n",
    "from random_forest_multitarget import RandomForestRegressor_Multi\n",
    "from dnn_model import DNN\n",
    "from dnn_single_model import DNN_Single"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dPh-gp4kzktf"
   },
   "source": [
    "def create_data(df,df_perf,labels):\n",
    "    df2 = df_perf.assign(label = labels['x'])\n",
    "    df2 = df2.rename(columns={'1' : 'Precision'})\n",
    "    data = df.join(df2.set_index('label'))\n",
    "    \n",
    "    return data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zCWm3xgtM5-s"
   },
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    df = df[df.replace([-np.inf], sys.float_info.min).notnull().all(axis=1)]\n",
    "    \n",
    "    return df[indices_to_keep].astype(np.float32)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nPAHs9A31Wzk"
   },
   "source": [
    "def get_data_for_algorith(algorithm, no_fold):\n",
    "  df_perf = pd.read_csv(f\"{target_data_folder}performance_0_I{algorithm}.txt\",sep='\\t')\n",
    "  df_train = pd.read_csv(f\"{features_data_folder}train_{no_fold}_fused.csv\",sep='\\t', index_col=0)\n",
    "  df_test = pd.read_csv(f\"{features_data_folder}test_{no_fold}_fused.csv\",sep='\\t', index_col=0)\n",
    "  df_perf = df_perf.iloc[:,2:3]\n",
    "\n",
    "  rez_test = create_data(df_test,df_perf,labels)\n",
    "  rez_train = create_data(df_train,df_perf,labels)\n",
    "  \n",
    "  return rez_train, rez_test"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p7BGjDuNXvwL"
   },
   "source": [
    "# Check valid data\n",
    "def valid_data(df):\n",
    "  if len(df[df.isin([np.nan, np.inf, -np.inf]).any(1)]) == 0:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N5bNAhhQ2-ep"
   },
   "source": [
    "def add_log_performance(df):\n",
    "  df['log_Precision'] = np.log10(df.iloc[:, -1] + 1)\n",
    "  return df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6x0SbvqsceXT"
   },
   "source": [
    "def get_features(X_train, y_train):\n",
    "  selected_features = [] \n",
    "  for i in range(0, len(y_train.columns)):\n",
    "      selector = SelectKBest(f_regression, k=10)\n",
    "      selector.fit(X_train, y_train.iloc[:,i])\n",
    "      #selected_features.append(list(selector.scores_))\n",
    "      cols = selector.get_support(indices=True)\n",
    "      selected_features.append(cols)\n",
    "\n",
    "  features = set()\n",
    "  for array in selected_features:\n",
    "    for feature in array:\n",
    "      features.add(feature)\n",
    "  return list(features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_RGdKw6_nj4f"
   },
   "source": [
    "def get_data(algorithm_no, fold):\n",
    "\n",
    "  if not isinstance(algorithm_no, list) and not isinstance(algorithm_no, tuple):\n",
    "    train_df, test_df = get_data_for_algorith(algorithm_no, fold)\n",
    "\n",
    "    train_df_with_log = add_log_performance(train_df)\n",
    "    test_df_with_log = add_log_performance(test_df) \n",
    "\n",
    "    train_df_with_log_clean = clean_dataset(train_df_with_log)\n",
    "    test_df_with_log_clean = clean_dataset(test_df_with_log)  \n",
    "\n",
    "    if valid_data(train_df_with_log_clean) and valid_data(test_df_with_log_clean):\n",
    "        X_train = train_df_with_log_clean.iloc[:, :-2]\n",
    "        y_train_labels = train_df_with_log_clean.iloc[:, -2:]\n",
    "\n",
    "        X_test = test_df_with_log_clean.iloc[:, :-2]\n",
    "        y_test_labels = test_df_with_log_clean.iloc[:, -2:]\n",
    "\n",
    "        return X_train, y_train_labels, X_test, y_test_labels\n",
    "    else:\n",
    "      raise Exception(\"Invalid Data\")\n",
    "\n",
    "  else:\n",
    "    data_train, data_test = [], []\n",
    "\n",
    "    for alg in algorithm_no:\n",
    "      d_train, d_test = get_data_for_algorith(alg, fold)\n",
    "      data_train.append(d_train)\n",
    "      data_test.append(d_test)\n",
    "\n",
    "    merged_good_train = data_train[0]\n",
    "    merged_good_test = data_test[0]\n",
    "\n",
    "    for i in range(1, len(algorithm_no)):\n",
    "      merged_train = pd.merge(merged_good_train, data_train[i], how='inner', left_index=True, right_index=True,\n",
    "                              suffixes=(f'_x{i}', f'_y{i}'))\n",
    "      merged_test = pd.merge(merged_good_test, data_test[i], how='inner', left_index=True, right_index=True,\n",
    "                             suffixes=(f'_x{i}', f'_y{i}'))\n",
    "\n",
    "      merged_good_train = merged_train[list(merged_train.columns[0:(100+i-1)]) + [merged_train.columns[-1]]]\n",
    "      merged_good_test = merged_test[list(merged_test.columns[0:(100+i-1)]) + [merged_test.columns[-1]]]\n",
    "\n",
    "    # Fix the column names\n",
    "    index = pd.Index(list(data_train[0].columns[:99]) + [f'Precision_alg{alg}' for alg in algorithm_no])\n",
    "    merged_good_train.columns = index\n",
    "    merged_good_test.columns = index\n",
    "\n",
    "    X_train = merged_good_train.iloc[:, :-len(algorithm_no)]\n",
    "    y_train_labels = merged_good_train.iloc[:, -len(algorithm_no):]\n",
    "\n",
    "    X_test = merged_good_test.iloc[:, :-len(algorithm_no)]\n",
    "    y_test_labels = merged_good_test.iloc[:, -len(algorithm_no):]\n",
    "\n",
    "    return X_train, y_train_labels, X_test, y_test_labels"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RgS6A2EKPoZT"
   },
   "source": [
    "def get_model(X_train, y_train, X_test, y_test, model_name, model_kwargs=None, single_output=True, target=None):\n",
    "  if model_kwargs is None:\n",
    "    model_kwargs = {}\n",
    "  if single_output:\n",
    "    if model_name == 'Xgboost':\n",
    "      return Xgboost_Single(X_train, y_train, X_test, y_test, model_kwargs, target)\n",
    "    elif model_name == 'nn':\n",
    "      return DNN_Single(X_train, y_train, X_test, y_test, target)\n",
    "    elif model_name == 'decision_tree':\n",
    "      return DecisionTree_Single(X_train, y_train, X_test, y_test, model_kwargs, target)\n",
    "    elif model_name == 'linear_regression':\n",
    "      return LinearRegression_Single(X_train, y_train, X_test, y_test, model_kwargs, target)\n",
    "    elif model_name == 'k_neighbors':\n",
    "      return KNeighborsRegressor_Single(X_train, y_train, X_test, y_test, model_kwargs, target)\n",
    "    elif model_name == 'random_forest':\n",
    "      return RandomForestRegressor_Single(X_train, y_train, X_test, y_test, model_kwargs, target)\n",
    "    else:\n",
    "      pass\n",
    "  else:\n",
    "    if model_name == 'Xgboost':\n",
    "      return Xgboost_Multi(X_train, y_train, X_test, model_kwargs, y_test)\n",
    "    elif model_name == 'nn':\n",
    "      return DNN(X_train, y_train, X_test, y_test)\n",
    "    elif model_name == 'decision_tree':\n",
    "      return DecisionTree_Multi(X_train, y_train, X_test, y_test, model_kwargs)\n",
    "    elif model_name == 'linear_regression':\n",
    "      return LinearRegression_Multi(X_train, y_train, X_test, y_test, model_kwargs)\n",
    "    elif model_name == 'k_neighbors':\n",
    "      return KNeighborsRegressor_Multi(X_train, y_train, X_test, y_test, model_kwargs)\n",
    "    elif model_name == 'random_forest':\n",
    "      return RandomForestRegressor_Multi(X_train, y_train, X_test, y_test, model_kwargs)\n",
    "    else: \n",
    "      pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dXvLUlCEW1kv"
   },
   "source": [
    "def dimension_reduction(x, n, dim_reduction_alg):\n",
    "  alg = dim_reduction_alg.lower()\n",
    "  alg_dict = {\n",
    "      'pca': PCA,\n",
    "      'svd': TruncatedSVD,\n",
    "      'isomap': Isomap, \n",
    "      'lle': LocallyLinearEmbedding\n",
    "  }\n",
    "  model = alg_dict[alg]\n",
    "  return model(n_components=n).fit_transform(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qXC3pngnGU0"
   },
   "source": [
    "## Multi output function\n",
    "model_name = 'physlearn' or 'Xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P-jJcOLRpsZ0"
   },
   "source": [
    "def run_50_folds_on_algorithm(algorithm_no, feature_selection = False, model_name='Xgboost', model_kwargs=None, dim_reduction_n=None, dim_reduction_alg='None', fold_range=None):\n",
    "  model_name_folder = model_name\n",
    "  if dim_reduction_alg and dim_reduction_n:\n",
    "    model_name_folder += f'_{dim_reduction_alg}_n_{dim_reduction_n}'\n",
    "  if model_kwargs:\n",
    "    model_name_folder += '_' + '_'.join(f'{k}={v}'for k, v in model_kwargs.items())\n",
    "    model_kwargs_str = '_'.join(f'{k}={v}'for k, v in model_kwargs.items())\n",
    "\n",
    "  if not isinstance(algorithm_no, list) and not isinstance(algorithm_no, tuple):\n",
    "    labels = ['Precision', 'log_Precision']\n",
    "    algorithm_name = str(algorithm_no)\n",
    "  else:\n",
    "    labels = [f'Precision_alg{i}' for i in algorithm_no]\n",
    "    algorithm_name = '_'.join(map(str, algorithm_no))\n",
    "\n",
    "  \n",
    "  predictions_folder = f\"/results/predictions/predictions_alg_no_{algorithm_name}/multi_target_output/{model_name_folder}/\"\n",
    "  mae_folder = f\"/results/mae/multi_target_output/{model_name_folder}/\"\n",
    "  models_folder = f'/results/models/multi_target_output/{model_name_folder}/'\n",
    "  os.makedirs(predictions_folder, exist_ok=True)\n",
    "  os.makedirs(mae_folder, exist_ok=True)\n",
    "  os.makedirs(models_folder, exist_ok=True)\n",
    "  output_mae = []\n",
    "\n",
    "  if fold_range is None:\n",
    "    fold_range = range(0, 50)\n",
    "\n",
    "  for i in fold_range:\n",
    "\n",
    "    # try:\n",
    "    X_train, y_train, X_test, y_test = get_data(algorithm_no, i)    \n",
    "\n",
    "    if feature_selection:\n",
    "\n",
    "      features = get_features(X_train, y_train)\n",
    "\n",
    "      X_train = X_train.iloc[:, features]\n",
    "      X_test = X_test.iloc[:, features]\n",
    "\n",
    "    if dim_reduction_alg and dim_reduction_n:\n",
    "      X_train = dimension_reduction(X_train, dim_reduction_n, dim_reduction_alg)\n",
    "      X_test = dimension_reduction(X_test, dim_reduction_n, dim_reduction_alg)\n",
    "\n",
    "    model = get_model(X_train, y_train, X_test, y_test, model_name, model_kwargs, False, None)\n",
    "\n",
    "    model.train_model()\n",
    "    \n",
    "    print(f\"PRINTING RESULTS FOR: fold number{i+1} and algorithm {algorithm_name}\\n\")\n",
    "    print(\"Testing score: \\n\")\n",
    "    \n",
    "    y_pred = model.get_predictions()\n",
    "\n",
    "    precision_mae = model.get_mae_precision()\n",
    "    print(f\"Precision MAE: {precision_mae:.4f}\")\n",
    "\n",
    "    log_precision_mae = model.get_mae_log_precision()\n",
    "    print(f\"Log Precision MAE: {log_precision_mae:.4f}\")\n",
    "\n",
    "    fold_algorithm_mae = [i, algorithm_name, precision_mae, log_precision_mae]\n",
    "    output_mae.append(fold_algorithm_mae)\n",
    "    \n",
    "    real_pred_df = model.get_df_with_predictions_for_csv(algorithm_name, i, labels)\n",
    "\n",
    "    real_pred_df.to_csv(f\"{predictions_folder}predictions_fold_no_{i}_alg_no_{algorithm_name}.csv\")\n",
    "    model_name_location = f'{models_folder}model_fold_no_{i}_alg_no_{algorithm_name}.pkl'\n",
    "    \n",
    "    if model_name == 'nn':\n",
    "      model_name_location = f'{models_folder}model_fold_no_{i}_alg_no_{algorithm_name}'\n",
    "      model.save_model(model_name_location)\n",
    "\n",
    "    else:\n",
    "      with open(model_name_location, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "\n",
    "    #except Exception as e:\n",
    "    #  print(\"EXCEPTION\")\n",
    "    #  print(e)\n",
    "\n",
    "  output_mae_df = pd.DataFrame(data=output_mae, columns=['Fold', 'Algorithm', 'Precision_mae', 'log_Precision_mae'])  \n",
    "  output_mae_df.to_csv(f'{mae_folder}mae_alg_no_{algorithm_name}_multi_output_model.csv')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuUTsvJN_7Bn"
   },
   "source": [
    "## Single output model function\n",
    "  algorithm_no -> number of algorithm "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W1CXPILAfzlh"
   },
   "source": [
    "def run_50_folds_on_algorithm_single_target(algorithm_no, feature_selection = False, model_name = 'Xgboost', model_kwargs=None, dim_reduction_n=None, dim_reduction_alg='None', fold_range=None):\n",
    "  model_name_folder = model_name\n",
    "  if dim_reduction_alg and dim_reduction_n:\n",
    "    model_name_folder += f'_{dim_reduction_alg}_n_{dim_reduction_n}'\n",
    "  if model_kwargs:\n",
    "    model_name_folder += '_' + '_'.join(f'{k}={v}'for k, v in model_kwargs.items())\n",
    "\n",
    "  if not isinstance(algorithm_no, list) and not isinstance(algorithm_no, tuple):\n",
    "    labels = ['Precision', 'log_Precision']\n",
    "    algorithm_name = str(algorithm_no)\n",
    "  else:\n",
    "    labels = [f'Precision_alg{i}' for i in algorithm_no]\n",
    "    algorithm_name = '_'.join(map(str, algorithm_no))\n",
    "\n",
    "  predictions_folder = f\"/results/predictions_alg_no_{algorithm_name}/single_output_models/{model_name_folder}/\"\n",
    "  mae_folder = f\"/results/mae/single_output_models/{model_name_folder}/\"\n",
    "  models_folder = f'/results/models/single_output_models/{model_name_folder}/'\n",
    "  os.makedirs(predictions_folder, exist_ok=True)\n",
    "  os.makedirs(mae_folder, exist_ok=True)\n",
    "  os.makedirs(models_folder, exist_ok=True)\n",
    "  output_mae = []\n",
    "  \n",
    "  if fold_range is None:\n",
    "      fold_range = range(0, 50)\n",
    "\n",
    "  for i in fold_range:  \n",
    "    #try:\n",
    "    X_train, y_train_labels, X_test, y_test_labels = get_data(algorithm_no, i) \n",
    "\n",
    "    if feature_selection:\n",
    "\n",
    "      features = get_features(X_train, y_train,)\n",
    "\n",
    "      X_train = X_train.iloc[:, features]\n",
    "      X_test = X_test.iloc[:, features]\n",
    "\n",
    "    if dim_reduction_alg and dim_reduction_n:\n",
    "      X_train = dimension_reduction(X_train, dim_reduction_n, dim_reduction_alg)\n",
    "      X_test = dimension_reduction(X_test, dim_reduction_n, dim_reduction_alg)\n",
    "\n",
    "    for label in labels:\n",
    "\n",
    "      y_train = y_train_labels[label]\n",
    "      y_test = y_test_labels[label]\n",
    "\n",
    "      model = get_model(X_train, y_train, X_test, y_test, model_name, model_kwargs, True, label)\n",
    "\n",
    "      model.train_model()\n",
    "      \n",
    "      print(f\"PRINTING RESULTS FOR: fold number{i+1} and algorithm {algorithm_name}\\n\")\n",
    "      print(\"Testing score: \\n\")\n",
    "      \n",
    "      y_pred = model.get_predictions()\n",
    "\n",
    "      mae = model.get_mae()\n",
    "      print(f\"{label} MAE: {mae:.4f}\")\n",
    "\n",
    "      fold_algorithm_mae = [i, algorithm_name, label, model_name, mae]\n",
    "      output_mae.append(fold_algorithm_mae)\n",
    "      \n",
    "      real_pred_df = model.get_df_with_predictions_for_csv(algorithm_name, i)\n",
    "      \n",
    "      real_pred_df.to_csv(f\"{predictions_folder}predictions_fold_no_{i}_alg_no_{algorithm_name}_label_{label}.csv\")\n",
    "      \n",
    "      model_name_location = f'{models_folder}model_fold_no_{i}_alg_no_{algorithm_name}_label_{label}.pkl'\n",
    "      if model_name == 'nn':\n",
    "        model_name_location = f'{models_folder}model_fold_no_{i}_alg_no_{algorithm_name}_label_{label}'\n",
    "        model.save_model(model_name_location)\n",
    "\n",
    "      else:\n",
    "        with open(model_name_location, 'wb') as file:\n",
    "          pickle.dump(model, file)\n",
    "          \n",
    "    # except Exception as e:\n",
    "    #   print(\"EXCEPTION\")\n",
    "    #   print(e)\n",
    "\n",
    "  output_mae_df = pd.DataFrame(data=output_mae, columns=['Fold', 'Algorithm', 'Label', 'Model', 'MAE'])  \n",
    "  output_mae_df.to_csv(f'{mae_folder}mae_alg_no_{algorithm_name}_single_output_models.csv')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kdy2NO1UwptH"
   },
   "source": [
    "random_forest_args_multi = {'n_estimators': 75, 'max_depth': 25, 'criterion': 'mae'}\n",
    "#random_forest_args_single = {'n_estimators': 25, 'max_depth': 25, 'criterion': 'mae'}\n",
    "#run_50_folds_on_algorithm_single_target([0, 1, 2], model_name='random_forest', model_kwargs=random_forest_args_single)\n",
    "run_50_folds_on_algorithm([0, 1, 2], model_name='random_forest', model_kwargs=random_forest_args_multi)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KALwDYeurugo"
   },
   "source": [
    "for i in range(3):\n",
    "  #run_50_folds_on_algorithm_single_target(i, model_name='nn')\n",
    "  run_50_folds_on_algorithm(i, model_name='nn')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrLRhKdvsYH-"
   },
   "source": [
    "## Run code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS0yxN-YnMcv"
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nroxN53nnPOj"
   },
   "source": [
    "for alg in [0, 1, 2]:\n",
    "  decision_tree_args = {'max_depth': 9, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm_single_target(alg, model_name='decision_tree', model_kwargs=decision_tree_args)\n",
    "\n",
    "  decision_tree_args = {'max_depth': 10, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm(alg, model_name='decision_tree', model_kwargs=decision_tree_args)\n",
    "\n",
    "  decision_tree_args = {'max_depth': 25, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm_single_target(alg, model_name='decision_tree', model_kwargs=decision_tree_args)\n",
    "\n",
    "  decision_tree_args = {'max_depth': 50, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm(alg, model_name='decision_tree', model_kwargs=decision_tree_args)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF51Qa7mnWAb"
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZZjKwQ-NnXwd"
   },
   "source": [
    "for alg in [0, 1, 2]:\n",
    "  random_forest_args = {'n_estimators': 10, 'max_depth': 7, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm_single_target(alg, model_name='random_forest', model_kwargs=random_forest_args)\n",
    "  \n",
    "  random_forest_args = {'n_estimators': 20, 'max_depth': 7, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm(alg, model_name='random_forest', model_kwargs=random_forest_args)\n",
    "\n",
    "  random_forest_args = {'n_estimators': 100, 'max_depth': 25, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm_single_target(alg, model_name='random_forest', model_kwargs=random_forest_args)\n",
    " \n",
    "  random_forest_args = {'n_estimators': 200, 'max_depth': 25, 'criterion': 'mae'}\n",
    "  run_50_folds_on_algorithm(alg, model_name='random_forest', model_kwargs=random_forest_args)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd4196SWqRyi"
   },
   "source": [
    "### Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PDuBfLDvsYIZ"
   },
   "source": [
    "for alg in [0, 1, 2]:\n",
    "  run_50_folds_on_algorithm_single_target(i, model_name='nn')\n",
    "  run_50_folds_on_algorithm(i, model_name='nn')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwO97LdfqcU9"
   },
   "source": [
    "### Decision tree for alg_no_0_1_2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DCBLltuxsYIa"
   },
   "source": [
    "random_forest_args = {'n_estimators': 25, 'max_depth': 25, 'criterion': 'mae'}\n",
    "run_50_folds_on_algorithm_single_target([0, 1, 2], model_name='random_forest', model_kwargs=random_forest_args)\n",
    "\n",
    "random_forest_args = {'n_estimators': 75, 'max_depth': 25, 'criterion': 'mae'}\n",
    "run_50_folds_on_algorithm([0, 1, 2], model_name='random_forest', model_kwargs=random_forest_args)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}